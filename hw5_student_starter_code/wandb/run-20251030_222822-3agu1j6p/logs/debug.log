2025-10-30 22:28:22,652 INFO    MainThread:94276 [wandb_setup.py:_flush():81] Current SDK version is 0.22.3
2025-10-30 22:28:22,652 INFO    MainThread:94276 [wandb_setup.py:_flush():81] Configure stats pid to 94276
2025-10-30 22:28:22,652 INFO    MainThread:94276 [wandb_setup.py:_flush():81] Loading settings from /jet/home/cchen36/.config/wandb/settings
2025-10-30 22:28:22,653 INFO    MainThread:94276 [wandb_setup.py:_flush():81] Loading settings from /ocean/projects/cis250233p/cchen36/Deep-Learning-Diffusion/hw5_student_starter_code/wandb/settings
2025-10-30 22:28:22,653 INFO    MainThread:94276 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-10-30 22:28:22,653 INFO    MainThread:94276 [wandb_init.py:setup_run_log_directory():706] Logging user logs to /ocean/projects/cis250233p/cchen36/Deep-Learning-Diffusion/hw5_student_starter_code/wandb/run-20251030_222822-3agu1j6p/logs/debug.log
2025-10-30 22:28:22,653 INFO    MainThread:94276 [wandb_init.py:setup_run_log_directory():707] Logging internal logs to /ocean/projects/cis250233p/cchen36/Deep-Learning-Diffusion/hw5_student_starter_code/wandb/run-20251030_222822-3agu1j6p/logs/debug-internal.log
2025-10-30 22:28:22,653 INFO    MainThread:94276 [wandb_init.py:init():833] calling init triggers
2025-10-30 22:28:22,653 INFO    MainThread:94276 [wandb_init.py:init():838] wandb.init called with sweep_config: {}
config: {'config': 'configs/ddpm_cifar10.yaml', 'data_dir': './data/cifar10/train', 'image_size': 128, 'batch_size': 16, 'num_workers': 8, 'num_classes': 100, 'run_name': 'ddpm_cifar10', 'output_dir': 'experiments', 'num_epochs': 200, 'learning_rate': 0.0002, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'seed': 42, 'mixed_precision': 'none', 'num_train_timesteps': 1000, 'num_inference_steps': 250, 'beta_start': 0.0001, 'beta_end': 0.01, 'beta_schedule': 'linear', 'variance_type': 'fixed_small', 'prediction_type': 'epsilon', 'num_inference_samples': 5000, 'samples_per_class': 50, 'clip_sample': True, 'clip_sample_range': 1.0, 'unet_in_size': 128, 'unet_in_ch': 3, 'unet_ch': 128, 'unet_ch_mult': [1, 2, 2, 4], 'unet_attn': [2, 3], 'unet_num_res_blocks': 2, 'unet_dropout': 0.0, 'latent_ddpm': False, 'use_cfg': False, 'cfg_guidance_scale': 2.0, 'use_ddim': False, 'ckpt': None, 'predictor_type': 'epsilon', 'distributed': False, 'world_size': 1, 'rank': 0, 'local_rank': 0, 'device': 'cuda', 'total_batch_size': 16, 'max_train_steps': 625000, '_wandb': {}}
2025-10-30 22:28:22,653 INFO    MainThread:94276 [wandb_init.py:init():881] starting backend
2025-10-30 22:28:25,211 INFO    MainThread:94276 [wandb_init.py:init():884] sending inform_init request
2025-10-30 22:28:25,318 INFO    MainThread:94276 [wandb_init.py:init():892] backend started and connected
2025-10-30 22:28:25,319 INFO    MainThread:94276 [wandb_init.py:init():962] updated telemetry
2025-10-30 22:28:25,362 INFO    MainThread:94276 [wandb_init.py:init():986] communicating run to backend with 90.0 second timeout
2025-10-30 22:28:26,111 INFO    MainThread:94276 [wandb_init.py:init():1033] starting run threads in backend
2025-10-30 22:28:27,192 INFO    MainThread:94276 [wandb_run.py:_console_start():2506] atexit reg
2025-10-30 22:28:27,192 INFO    MainThread:94276 [wandb_run.py:_redirect():2354] redirect: wrap_raw
2025-10-30 22:28:27,192 INFO    MainThread:94276 [wandb_run.py:_redirect():2423] Wrapping output streams.
2025-10-30 22:28:27,192 INFO    MainThread:94276 [wandb_run.py:_redirect():2446] Redirects installed.
2025-10-30 22:28:27,337 INFO    MainThread:94276 [wandb_init.py:init():1073] run started, returning control to user process
