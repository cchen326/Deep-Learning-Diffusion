# Resume from 50 epochs and train to 200 total
run_name: ddim_imagenet128_long_run_with_cfg_cosine
num_epochs: 200  # Total epochs (will train epochs 51-200)

# Point to your last checkpoint



seed: 42
data_dir: /ocean/projects/cis250233p/cchen36/Deep-Learning-Diffusion/hw5_student_starter_code/data/imagenet100_128x128/train
image_size: 128
batch_size: 64        # per GPU
num_workers: 8
num_classes: 100
#num_epochs: 100
learning_rate: 2e-4
weight_decay: 1e-4

num_train_timesteps: 1000
num_inference_steps: 250
num_inference_samples: 5000
samples_per_class: 50
beta_start: 1e-4
beta_end: 1e-2
beta_schedule: cosine

variance_type: fixed_small
predictor_type: epsilon

unet_in_size: 128
unet_in_ch: 3
unet_ch: 128
unet_num_res_blocks: 2
unet_ch_mult: [1, 2, 2, 4]   # four stages for 128Ã—128
unet_attn: [2, 3]            # add attention on top two scales
unet_dropout: 0.0

use_ddim: True
use_cfg: True               # flip to True later if you add class emb.